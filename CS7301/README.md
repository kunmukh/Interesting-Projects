# AGE-GNN: Adversarial Generator using Graph Neural Network for ML Evasion

## Resource

- Paper:

- Dataset for training/testing/validation:

- Code: See [Doc2Vec](Doc2Vec), [AutoEncoder](AutoEncoder), [LOF](LOF), [Gadget](Gadget)

- Pre-trained Model:

## INTRODUCTION

Signature-based and network-based fail miserable against stealthy attacks such as **zero-day vulnerability**, **malware mutants** and **advanced persistent threats (APTs) attacks**. Simple machine Learning based detectors such as SVM, PCA, ensemble methods such as bagging/boosting and **local outlier factor(LOF)** have been used to detect these advanced threats but they have also been defeated by specifically crafted APTs. Current and on-going work has been using two prominent ML technique called **Variational Auto Encoders(VAE)** and Graph Neural Network(GNN) based anomaly detection.

We propose AGE-GNN, a systematic approach that re-examines the current practices of ML-based security by considering **advanced active adversaries** who focus on exploiting the weaknesses of ML based security  through evasive attacks. In particular, we assume an adversary who seeks to extend the **APT-style attack campaign** by integrating a series of **advanced attack vectors** into a single attack scenario to avoid being detected by the ML-based security model. The
adversary uses system data to replace the attack vectors with attack constructs which we name as **APT-gadget** (or in short *gadget*). In this sense, the APT-gadget defines a structure that carries **malicious semantics** when executed in reference to the APT-attack but is naturally deemed **benign within the context** of the target system. We evaluated AGE-GNN with a **realistic APT scenario** to confirm our research insight.

### ML BASED DETECTION FRAMEWORK
<img src="./assets/ml-detection-workflow.png" alt=": Detection workflow of ML based detector"   width="700"/>

The Machine Learning framework for different models have different specifics but the overall framework is same. They first train a model with **benign system** activity and then uses it to classify system activities with the goal that system or user process that have been *hijacked* by malware(e.g., attacker) will show *abnormal system activity* that can be identified. It is clear that for attackers to cause harm or do their bidding, they will have to interact with system entities like files, network sockets and processes. These **interaction or behavior** would be **different** than the benign program‚Äôs normal behavior and this insights has motivated the latest ML based detection models.

## MOTIVATIONAL APT ATTACK STUDY
<img src="./assets/apt.png" alt="Provenance graph for APT attack vs APT with gadget"   width="500"/>

The phishing email attack can be classified according to MITRE ATT&CK framework into five major TTPs: **Initial Access, Establishing a Foothold, Privilege Escalation, Deepen Access, and Exfiltration**. We conduct the five TTPs using the well-known penetration testing framework, *msfconsole*. The attack involves an attacker crafting a malicious macro (e.g., malware named java.exe) embedded attachment (e.g., Excel document) which is sent to a victim through email. The **first TTP**, Initial Access, is realized when the victim *downloads* and opens the email attachment.

The malicious macro starts a new malware process called java.exe which opens an initial connection with the attacker‚Äôs C&C. The attacker runs specialized software to *get the password hashes and LSA secrets*. The **second TTP**, Establishing a Foothold, is realized here. The  attacker use the password hashes and username to attack the domain controller host running on port 445 as well as try to exploit it. Once the Windows active directory (e.g., domain controller) is exploited, the attacker can easily open a *privileged command prompt* (e.g., cmd.exe) using the credentials thus completing the **third TTP** of Privilege Escalation.

After launching a privileged shell, the attacker conducts a *network scan* to find and connect to the SQL server. The **fourth TTP**, Deepen Access, is realized here as the attacker tries to penetrate the enterprise and infect more victims. Once the SQL server is located, the attacker executes a malicious visual basic script file using cscript.exe to creates another malware instance. This malware process executes SQL commands in the privileged shell using osql.exe and sqlservr.exe. Finally, the attacker *downloads* the database dumps generated by the command completing the **fifth TTP** of exfiltration.

## APPROACH

### GADGET FINIDING & RANKING
The **regularity score** of a system event shows the probability of a specific system event occurring. If event ùëí has never occurred in the system, then the value of ùëÖ(ùëí) is 0 indicating that ùëí is a rare system event. Therefore, the regularity score of a causal path ùúÜ is dependent on the regulatory score of its constituent system events, {ùëí1, ùëí2,...,ùëíùëõ}. Thus, a causal path composed of many **rare** system event would have a **low regularity score**, resulting in a **higher probability** of detection.

Gadgets are unique to the **specific behavioral profile** of a given system and directly depend on the actions of the native processes within. For this purpose, **common programs** with a high frequency in the target system along with common benign profiles make good candidates for gadgets. The **graph neural network(GNN)** is trained using **benign system** events that has the same frequency distribution as the victim, therefore the **gadget** the GNN would **recommend** will have a **high** frequency, therefore it will have a **high** regulatory score.

<img src="./assets/gadget-rank.png" alt="APT attack stages using gadget chain and their regularity score"   width="800"/>

### GADGET APT ATTACK CREATION
The purpose of AGE-GNN is to find system events with **high regularity scores** that can be used as gadgets to replace events in an attack with a lower regularity score. In this way, the overall regularity score of the entire attack path will **increase**, making it **harder** to detect as shown in Table 2. We formalize our problem statement as finding the top K popular system events with high regularity scores that can be used to replace rare paths in an APT attack.

<img src="./assets/gadget-find.png" alt="Regularity Score calculation for causal paths for APT attack vs APT attack with gadgets"   width="500"/>

## DATASET

### Benign Dataset

We selected **30 system programs** from our event database that are commonly used in APT campaigns also mentioned in previous studies such as *ProvDetector*. The provenance graphs generated from the benign system programs consisted of **4735.30 causal paths, 37.51 vertices and 45.78 edges** on average (Table 3). The provenance graph generated from the benign user application consisted of **11779.36 causal paths, 90.36 vertices and 112.38 edges** on average (Table 3).

<img src="./assets/benign-data.png" alt="Number of vertex and edges used to create benign profile for system programs"   width="500"/>

### Malicious Dataset
The anomaly dataset contains two datasets: **APT attack campaign** and **APT attack campaign with gadget**. The APT attack campaign with gadget consists of the APT attack that was conducted using the gadget mentioned in column events in APT Stages using Gadget Chain 1 Table 2. We used a malicious testbed to collect labeled datasets necessary for prediction tasks by running **five different kinds of APT attack stages** with and without gadgets. 

The provenance graphs for *APT Kill Chain Scenario* contains an average of **493.92 causal paths, 94.78 vertices and 97.48 edges**. The provenance graphs for *APT Kill Chain Scenario with Gadget* has an average of **175.93 causal paths, 30.39 vertices and 29.50 edges**.

<img src="./assets/mal-data.png" alt="Number of vertex and edges used to create malicious APT and gadget APT profile"   width="500"/>

## EVALUATION

### Detection Accuracy

The detection accuracy of the APT attack stages by different MLbased behavioral analysis is measured in precision, recall, and F1 score. The autoencoder‚Äôs recall and F1 scores under APT Kill Chain Scenario range from 0.99 to 1.0 and 0.95 to 1.0, respectively. This means that the autoencoder is **extremely proficient in detecting anomalous causal paths**. The LOF model‚Äôs recall and F1 scores under APT Kill Chain Scenario range from 0.75 to 0.82 and 0.85 to 0.90 respectively. The relatively low recall and F1 scores compared to the autoencoder means that LOF **cannot** easily detect anomalous causal paths.

The autoencoder‚Äôs recall and F1 scores range from 0.09 to 0.24 and 0.16 to 0.39 respectively against the APT Kill Chain with Gadget suggesting that the **detection capability of the autoencoder model was significantly decreased** when gadget was used. LOF‚Äôs recall and F1 scores range from 0.02 to 0.20 and 0.05 to 0.34, respectively which also suggest that the anomaly detection capability of LOF against APT Kill Chain with Gadget was decreased to a great extent when gadget was used.

<img src="./assets/result-1.png" alt=": ML-based behavior models‚Äô (LOF and autoencoder) detection results for APT attack and APT attack with gadget"   width="400"/>

### Degree of Evasiveness for APT Stages

Using the F1 scores in Figure 4 and Figure 5, we can list the APT attack stages from *easiest to hardest* to detect: exfiltration, deepen access, establish a foothold, privilege escalation, and initial access.

<img src="./assets/result-2.png" alt="F1 score for APT attack stage with gadget detection"   width="400"/>

# Citation

```
@Inproceedings{kunal2021,
author = {Mukherjee, Kunal},
title = {AGE-GNN: Adversarial Generator using Graph Neural Network for ML Evasion},
year = {2021},
isbn = {},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {},
doi = {},
booktitle = {Proceedings of the ACM/IEEE 43nd International Conference on Software Engineering},
pages = {},
numpages = {13},
keywords = {System Security, Variational AutoEncoders, Graph Neural Network,
Adversarial Example},
location = {},
series = {CCS '21}
}
```
